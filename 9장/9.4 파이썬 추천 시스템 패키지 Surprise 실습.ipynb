{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Surprise - 파이썬 추천 패키지</h1>\n",
    "\n",
    "\n",
    "<img src=\"./img/SuprisePackage1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Surprise 패키지를 이용한 추천 수행 프로세스</h2>\n",
    "\n",
    "데이터를 Dataset이라는 객체로 로딩을 한다. 그리고 모델 설정 및 학습을 하여 행렬 기반분해(SVD)를 할거냐 아이템 기반의 협업 필터를 할거냐\n",
    "\n",
    "(KNNBasic)를 설정한다. 그 다음에 학습을 한다(train()메소드) 그 다음에 예측 및 평가를 한다.\n",
    "\n",
    "약간 사이킷런이랑 다른게 test()와 predict()가 있는데 사이킷런의 predict()이랑 같은건 test()이다. \n",
    "\n",
    "입력 인자에서 들어온 모든 dataset에 대한 예측 평가를 해주는데 predict()는 한건만 해준다.\n",
    "\n",
    "그리고 cross_validate를 할 수 있고 GridSerchCV로 하이퍼 파라미터 튜닝과 cross_validation을 함께 할 수 있다.\n",
    "\n",
    "조금 유의할 점은 데이터 로딩 부분인데, Surprise 패키지는  '반드시 이런 데이터 유형으로 들어와야 됩니다'라고 고정이 되어있는게 있는데\n",
    "\n",
    "UserId, ItemId, rating이 Raw 레벨로 되어있어야 한다. \n",
    "\n",
    "<img src = \"./img/SurpriseProcess.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Surprise를 이용한 추천 구현 기본</h2>\n",
    "\n",
    "순서는 이렇다\n",
    "\n",
    "앞에랑의 차이가, 사이킷런은 predict였는데 surprise는 test()이다. 결과가 리스트 형으로 나온다.\n",
    "\n",
    "\n",
    "<img src = \"./img/SurpriseRecom1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Surprise 주요 모듈 소개 - Dataset</h2>\n",
    "\n",
    "Surprise는 기본적으로 Fix된 형태를 가져간다고 했다.(low 레벨로)\n",
    "\n",
    "우리가 지금까지 학습을 했던거는 pivot_table을 해서 바꿨었다.\n",
    "\n",
    "하지만 입력 자체는 이렇게 Raw 레벨로 되어있어야 한다. Raw 레벨로 데이터가 들어가게 되면 데이터셋이 알아서 변환을 해준다.\n",
    "\n",
    "그리고 첫번째 두번째 세번째 칼럼을  무조건 사용자 I 아이템 ID Rating으로 하고 4번째부터는 아예 관여를 하지 않는다.\n",
    "\n",
    "<img src = \"./img/SurpriseDataset.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dataset 클래스의 주요 메소드</h2>\n",
    "\n",
    "대표적으로 load_builtin 이게 있다. 알아서 다 맞춰준다. \n",
    "\n",
    "무비렌즈 데이터 같은 내장 데이터 말고 일반적으로 OS 파일이나 데이터프레임에서 로딩을 한다.\n",
    "\n",
    "load_from_file을 쓰면 file_path:파일이 어디 있는지 두번째는 reader: 이 클래스를 이용하면 포맷팅을 해준다. 뒤에서 설명함.\n",
    "\n",
    "load_from_df도 마찬가지. df: 입력으로 데이터 프레임을 넣어주고 reader: 이 데이터 프레임이 어떤 포맷으로 되어있습니다 라고 지정 해준다.\n",
    " \n",
    "<img src = \"./img/DatasetMethod.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Surprise 주요 모듈 소개 - Reader</h2>\n",
    "\n",
    "이런 데이터 세트를 데이터 셋으로 로드하기 위해서 미리 사전에 데이터 폼에서 지정을 해준다. 어떻게 하냐면\n",
    "\n",
    "line_format = \"1컬럼 2컬럼 3컬럼 4컬럼 에서 자동으로 첫번재 userId 두번재 ItemId 세번째는 평점으로 자동적으로 인지를 하게 된다.\n",
    "\n",
    "지금까지했던 무비렌즈는 최소평점이 0.5~5인데 안그럴 수도 있다. 안 그런 경우에는 rating_scale로 지정해주면 된다.\n",
    "\n",
    "load_from_file로 파일 디렉토리를 지정해주고 reader를 호출하면 여기 있는 파일을 reader 폼에 맞춰서 입력하게 된다.\n",
    "\n",
    "근데 sep을 보면 디폴트가 탭이다(탭키) 왜 그럴까? 실습할 때 얘기나오는데 과거 모듈 데이터 셋이라 그땐 디폴트가 탭이었다.\n",
    "\n",
    "<img src = \"./img/SurpriseModule.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>서프라이즈를 이용해 기본 추천 구현 실습</h1><br><br>\n",
    "\n",
    "[Supriselib 바로가기](https://supriselib.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "# 서프라이즈 버전 확인\n",
    "import surprise \n",
    "\n",
    "print(surprise.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise 를 이용한 추천 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD # 추천 알고리즘\n",
    "from surprise import Dataset #원본 raw 데이터를 서프라이즈에 적합한 데이터 셋으로 만들어주는 것\n",
    "from surprise import accuracy # 이 모듈안에 rmse가 있으므로 그걸로 평가할 것\n",
    "from surprise.model_selection import train_test_split # 이걸로 학습, 테스트 데이터 셋 분리할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**내장 데이터를 로드하고 학습과 테스트 데이터로 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin('ml-100k') \n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**추천 행렬 분해 알고리즘으로 SVD객체를 생성하고 학습수행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1e4709c0dd8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**테스트 데이터 세트에 예상 평점 데이터 예측. test()메소드 호출 시 Prediction 객체의 리스트로 평점 예측 데이터 반환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction type : <class 'list'>  size: 25000\n",
      "prediction 결과의 최초 5개 추출\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='120', iid='282', r_ui=4.0, est=3.7655400341312286, details={'was_impossible': False}),\n",
       " Prediction(uid='882', iid='291', r_ui=4.0, est=3.6061742294724124, details={'was_impossible': False}),\n",
       " Prediction(uid='535', iid='507', r_ui=5.0, est=4.204219862347287, details={'was_impossible': False}),\n",
       " Prediction(uid='697', iid='244', r_ui=5.0, est=3.6596559285045807, details={'was_impossible': False}),\n",
       " Prediction(uid='751', iid='385', r_ui=4.0, est=3.1710828572267284, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test(testset)\n",
    "print('prediction type :',type(predictions), ' size:',len(predictions))\n",
    "print('prediction 결과의 최초 5개 추출')\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확인해보니 list 클래스이고 25000개의 원소를 가진다. 5개만 추출해서 어떤 데이터가 들어가있는지 확인해보니까\n",
    "\n",
    "Prediction 객체가 들어가 있고 uid, iid, r_ui(실제 평점) est(예측평점). 이런 세트가 25000개 리스트에 들어가 있는거다.\n",
    "\n",
    "r_ui는 필요없으니까 아래처럼 간단히 뽑을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120', '282', 3.7655400341312286),\n",
       " ('882', '291', 3.6061742294724124),\n",
       " ('535', '507', 4.204219862347287)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (pred.uid, pred.iid, pred.est) for pred in predictions[:3] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**predict()메소드는 개별 사용자,아이템에 대한 예측 평점 정보를 반환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = None   est = 4.03   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# 사용자 아이디, 아이템 아이디는 문자열로 입력해야 함. \n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "객체 하나만 반환된거다. item 302에 대해서 평가를 하진 않았지만 est(estimate)는 4.08이다 라는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**반환된 Prediction의 리스트 객체를 기반으로 RMSE 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9474254414864771"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise 주요 모듈 소개\n",
    "**csv 파일로 사용자 평점 데이터 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "# ratings_noh.csv 파일로 unload 시 index 와 header를 모두 제거한 새로운 파일 생성.  \n",
    "ratings.to_csv('./ml-latest-small/ratings_noh.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reader클래스로 파일의 포맷팅 지정하고 Dataset의 load_from_file()을 이용하여 데이터셋 로딩**\n",
    "\n",
    "csv 파일이라고 알려줘야 하므로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "data=Dataset.load_from_file('./ml-latest-small/ratings_noh.csv',reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**학습과 테스트 데이터 세트로 분할하고 SVD로 학습후 테스트데이터 평점 예측 후 RMSE평가**\n",
    "\n",
    "이제 앞에하고 똑같다. 똑같은데 다른게 뭐냐면 앞에는 SVD에 디폴트를 했다.\n",
    "\n",
    "여기선 n_factor = 50개를 줄거다. 이건 앞에서의 K 값임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "# 수행시마다 동일한 결과 도출을 위해 random_state 설정 \n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "\n",
    "# 학습 데이터 세트로 학습 후 테스트 데이터 세트로 평점 예측 후 RMSE 평가\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**판다스 DataFrame기반에서 동일하게 재 수행**\n",
    "\n",
    "이것도 똑같다. 대신 load_from_df (df에서 바로 로드하겠다는 함수를 호출)\n",
    "\n",
    "reader에 별 지정을 안했다. 데이터프레임은 그럴 필요가 없다. 그냥 데이터 프레임만 넣어주면 됨. 그리고 reader는 스케일만 넣어준다.\n",
    "\n",
    "**단 사용자 아이디, 아이템 아이디, 평점 순서를 반드시 지켜야 한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv') \n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# ratings DataFrame 에서 컬럼은 사용자 아이디, 아이템 아이디, 평점 순서를 지켜야 합니다. \n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Surprise 추천 알고리즘 클래스</h1>\n",
    "\n",
    "서프라이즈를 조금 더 파고 들어보자.\n",
    "\n",
    "대표적인 클래스는\n",
    "\n",
    "SVD: 행렬 분해\n",
    "\n",
    "KNNBasic: 사용자 기반이냐 아이템 기반이냐에 따라서 최근접(K-nearest)\n",
    "\n",
    "BaselineOnly: 사용자 Bias 아이템 Bias를 감안\n",
    "\n",
    "[지원 알고리즘은 suprise 사이트 문서 참조](http://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)\n",
    "\n",
    "<img src=\"./img/SurpriseAlgoClass.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>사용자의 성향을 반영한 Baseline rating</h2>\n",
    "\n",
    "특정 사용자 u가 아직 평가를 하지 않은 아이템 i 에 대해 어떻게 평점을 내리냐면 왼쪽 수식대로이다.\n",
    "\n",
    "사용자의 성향을 반영하는거다. 평점을 줄때 깐깐한 사람이라던가. \n",
    "\n",
    "<img src=\"./img/BaselienRating.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Baseline rating을 반영한 행렬 분해의 비용 최소화 함수</h2>\n",
    "\n",
    "SVD를 SGD를 할 때 사용자 baseline rating을 안했었으나 일반적으로는 감안해서 한다.\n",
    "\n",
    "b^i+ b^2u를 최소화할 수 있는 p값과 q 값을 구해서 계속 업데이트를 시키는데 Gradient decent 방식\n",
    "\n",
    "<img src=\"./img/BaselienRating1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SVD의 튜닝 파라미터</h2>\n",
    "\n",
    "3개 밖에 없다.\n",
    "\n",
    "n_factors: K개 차원. 이게 몇개냐. 이걸 크게할 수록 정확도는 높아질 수 밖에 없다(원래 차원으로 가므로..)그러나 과적합 문제 발생.\n",
    "\n",
    "n_epochs: SGD 반복 횟수. 디폴트 20\n",
    "\n",
    "biased (bool): 디폴트는 True인데 베이스라인 편향을 적용할거냐 안할거냐.\n",
    "\n",
    "<img src=\"./img/SVDParam.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>교차 검증과 하이퍼 파라미터 튜닝</h2>\n",
    "\n",
    "**Surprise는 교차 검증과 하이퍼 파라미터 튜닝을 위해 사이킷런과 유사한 cross_validate()와 GridSearchCV 클래스를 제공합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증(Cross Validation)과 하이퍼 파라미터 튜닝\n",
    "\n",
    "**cross_validate()를 이용한 교차 검증**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8718  0.8808  0.8740  0.8738  0.8641  0.8729  0.0053  \n",
      "MAE (testset)     0.6703  0.6768  0.6722  0.6709  0.6642  0.6709  0.0040  \n",
      "Fit time          3.12    3.12    3.12    3.11    3.13    3.12    0.01    \n",
      "Test time         0.10    0.12    0.12    0.09    0.08    0.10    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.87184373, 0.88075985, 0.87400287, 0.87383202, 0.86408146]),\n",
       " 'test_mae': array([0.6702703 , 0.67679466, 0.67219773, 0.67091898, 0.66422805]),\n",
       " 'fit_time': (3.124035358428955,\n",
       "  3.116971969604492,\n",
       "  3.123969316482544,\n",
       "  3.1050002574920654,\n",
       "  3.126000165939331),\n",
       " 'test_time': (0.09600687026977539,\n",
       "  0.12303042411804199,\n",
       "  0.125,\n",
       "  0.08597135543823242,\n",
       "  0.08499884605407715)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate \n",
    "\n",
    "# Pandas DataFrame에서 Surprise Dataset으로 데이터 로딩 \n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv') # reading data in pandas df\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "algo = SVD(random_state=0) \n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE, MAE에 대해서 개별 폴드셋 별로 개별적인 스코어가 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV 이용**\n",
    "\n",
    "유사하다. param_grid를 통해서 앞에 세개의 SVD 행렬 분해 방식의 n_epochs, n_factors. bias는 기본적으ㅜ로 가져간다.\n",
    "\n",
    "그리고 GridSearchCV를 생성하는데 유의해야 할게 있다. SVD라고 그냥 클래스 명이 들어간다. 쉬프트 탭을 눌러서 한번 보자.\n",
    "\n",
    "이걸 만약에 Algo 이렇게 넣으면 오류가 난다. Algo는 위에 보면 이미 초기화가 들어간다.\n",
    "\n",
    "그리고 best_score. 약간 사이킷런에서랑 다르다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8781543551293467\n",
      "{'n_epochs': 20, 'n_factors': 50}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# 최적화할 파라미터들을 딕셔너리 형태로 지정. \n",
    "param_grid = {'n_epochs': [20, 40, 60], 'n_factors': [50, 100, 200] }\n",
    "\n",
    "# CV를 3개 폴드 세트로 지정, 성능 평가는 rmse, mse 로 수행 하도록 GridSearchCV 구성\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# 최고 RMSE Evaluation 점수와 그때의 하이퍼 파라미터\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise 를 이용한 개인화 영화 추천 시스템 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD 학습은 TrainSet 클래스를 이용해야 함**\n",
    "\n",
    "먼저 전에 안보던 클래스를 써야한다. DatasetAutoFolds라는 클래스.\n",
    "\n",
    "이전에는 train_test_splits으로 나눠서 train 세트에 SVD를 fit했었다. \n",
    "\n",
    "이렇게 안나누고 그냥하면 받아들이지 못한다. 근데 분리를 안하고 하는 방법이 있다.\n",
    "\n",
    "그게 바로 DatasetAutoFolds라는 것임.  데이터셋 로딩하는거랑 똑같은데 그 앞에 이것만 들어갔다.\n",
    "\n",
    "전체 데이터를 학습데이터로 생성할 수 있음. 이게 앞에 했던거랑 살짝 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetAutoFolds' object has no attribute 'global_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-33c08dace4bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'movieId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pygta5\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetAutoFolds' object has no attribute 'global_mean'"
     ]
    }
   ],
   "source": [
    "# 아래 코드는 train_test_split( )으로 분리되지 않는 Dataset에 fit( )을 호출하여 오류를 발생합니다.\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DatasetAutoFolds를 이용한 전체 데이터를 TrainSet클래스 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "# DatasetAutoFolds 클래스를 ratings_noh.csv 파일 기반으로 생성. \n",
    "data_folds = DatasetAutoFolds(ratings_file='./ml-latest-small/ratings_noh.csv', reader=reader)\n",
    "\n",
    "#전체 데이터를 학습데이터로 생성함. \n",
    "trainset = data_folds.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD로 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1e47205d080>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_epochs=20, n_factors=50, random_state=0)\n",
    "algo.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 되었다.\n",
    "\n",
    "이제 rating이 아니라 movies.csv로 영화에 대한 타이틀 정보를 필터링하기 위해서 데이터프레임으로 로딩할거다.\n",
    "\n",
    "그리고 9번 유저. 이 9번 유저에 대해서 특정 영화들을 추천할거다.\n",
    "\n",
    "영화 42의 평점을 어떻게 먹이는지 한번 보자.(아직 9번 유저가 평가하지 않았음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 아이디 9는 영화 아이디 42의 평점 없음\n",
      "    movieId                   title              genres\n",
      "38       42  Dead Presidents (1995)  Action|Crime|Drama\n"
     ]
    }
   ],
   "source": [
    "# 영화에 대한 상세 속성 정보 DataFrame로딩\n",
    "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
    "\n",
    "# userId=9 의 movieId 데이터 추출하여 movieId=42 데이터가 있는지 확인. \n",
    "movieIds = ratings[ratings['userId']==9]['movieId']\n",
    "if movieIds[movieIds==42].count() == 0:\n",
    "    print('사용자 아이디 9는 영화 아이디 42의 평점 없음')\n",
    "\n",
    "print(movies[movies['movieId']==42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 9          item: 42         r_ui = None   est = 3.13   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(9)\n",
    "iid = str(42)\n",
    "\n",
    "pred = algo.predict(uid, iid, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 내용: 9 번 사용자에 대해서 42번 아이템에 대해서 예측 평점을 추측해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 매긴 영화수: 46 추천대상 영화수: 9696 전체 영화수: 9742\n"
     ]
    }
   ],
   "source": [
    "def get_unseen_surprise(ratings, movies, userId):\n",
    "    #입력값으로 들어온 userId에 해당하는 사용자가 평점을 매긴 모든 영화를 리스트로 생성\n",
    "    seen_movies = ratings[ratings['userId']== userId]['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화들의 movieId를 리스트로 생성. \n",
    "    total_movies = movies['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화들의 movieId중 이미 평점을 매긴 영화의 movieId를 제외하여 리스트로 생성\n",
    "    unseen_movies= [movie for movie in total_movies if movie not in seen_movies]\n",
    "    print('평점 매긴 영화수:',len(seen_movies), '추천대상 영화수:',len(unseen_movies), \\\n",
    "          '전체 영화수:',len(total_movies))\n",
    "    \n",
    "    return unseen_movies\n",
    "\n",
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 surprise를 통해서 추천을 할거다.\n",
    "\n",
    "prediction을 할건데 개별영화를 반복적으로 호출하면서 할거다. \n",
    "\n",
    "무슨 얘끼냐면 unseen_movies에 평점을 46개 먹였으니까 전체 9742개중에 9696개는 추천영화 중에 들어갈 수 있다.\n",
    "\n",
    "리스트 컴프리헨션으로 루프를 돌면서 algo.predict를 호출하세요 라는 코드(predictions)로."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 매긴 영화수: 46 추천대상 영화수: 9696 전체 영화수: 9742\n",
      "##### Top-10 추천 영화 리스트 #####\n",
      "Usual Suspects, The (1995) : 4.306302135700814\n",
      "Star Wars: Episode IV - A New Hope (1977) : 4.281663842987387\n",
      "Pulp Fiction (1994) : 4.278152632122759\n",
      "Silence of the Lambs, The (1991) : 4.226073566460876\n",
      "Godfather, The (1972) : 4.1918097904381995\n",
      "Streetcar Named Desire, A (1951) : 4.154746591122658\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) : 4.122016128534504\n",
      "Star Wars: Episode VI - Return of the Jedi (1983) : 4.108009609093436\n",
      "Goodfellas (1990) : 4.083464936588478\n",
      "Glory (1989) : 4.07887165526957\n"
     ]
    }
   ],
   "source": [
    "def recomm_movie_by_surprise(algo, userId, unseen_movies, top_n=10):\n",
    "    # 알고리즘 객체의 predict() 메서드를 평점이 없는 영화에 반복 수행한 후 결과를 list 객체로 저장\n",
    "    predictions = [algo.predict(str(userId), str(movieId)) for movieId in unseen_movies]\n",
    "    \n",
    "    # predictions list 객체는 surprise의 Predictions 객체를 원소로 가지고 있음.\n",
    "    # [Prediction(uid='9', iid='1', est=3.69), Prediction(uid='9', iid='2', est=2.98),,,,]\n",
    "    # 이를 est 값으로 정렬하기 위해서 아래의 sortkey_est 함수를 정의함.\n",
    "    # sortkey_est 함수는 list 객체의 sort() 함수의 키 값으로 사용되어 정렬 수행.\n",
    "    def sortkey_est(pred):\n",
    "        return pred.est\n",
    "    \n",
    "    # sortkey_est( ) 반환값의 내림 차순으로 정렬 수행하고 top_n개의 최상위 값 추출.\n",
    "    predictions.sort(key=sortkey_est, reverse=True)\n",
    "    top_predictions= predictions[:top_n]\n",
    "    \n",
    "    # top_n으로 추출된 영화의 정보 추출. 영화 아이디, 추천 예상 평점, 제목 추출\n",
    "    top_movie_ids = [ int(pred.iid) for pred in top_predictions]\n",
    "    top_movie_rating = [ pred.est for pred in top_predictions]\n",
    "    top_movie_titles = movies[movies.movieId.isin(top_movie_ids)]['title']\n",
    "    top_movie_preds = [ (id, title, rating) for id, title, rating in zip(top_movie_ids, top_movie_titles, top_movie_rating)]\n",
    "    \n",
    "    return top_movie_preds\n",
    "\n",
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)\n",
    "top_movie_preds = recomm_movie_by_surprise(algo, 9, unseen_movies, top_n=10)\n",
    "print('##### Top-10 추천 영화 리스트 #####')\n",
    "\n",
    "for top_movie in top_movie_preds:\n",
    "    print(top_movie[1], \":\", top_movie[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
