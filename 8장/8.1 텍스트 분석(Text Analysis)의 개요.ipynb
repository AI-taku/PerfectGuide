{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>텍스트 분석 이해 NLP와 텍스트 분석</h1>\n",
    "\n",
    "요즘 같은 머신러닝이 발전한 시대에 NLP와 텍스트 분석(텍스트 마이닝)을 구분하는것은 의미가 없을 수도 있지만 굳이 해보자.\n",
    "\n",
    "<img src=\"./img/TextAnalysis1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>텍스트 분석 주요 영역</h2><br>\n",
    "\n",
    "\n",
    "|                                 |                          |\n",
    "|:------------------------------:|:-------------------------:|\n",
    "|텍스트 분류(Text Classification)|문서가 특정 분류 또는 카테고리에 속하는 것을 예측하는 기법을 통칭. 예: 특정 신문기사 내용이 연애/ 정치/ 사회/ 문화 중 어떤 카테고리에 속하는지 자동으로 분류하거나 스팸 메일 검출 같은 프로그램들. 지도학습을 적용|\n",
    "|감성분석(Sentiment Analysis) | 텍스트에서 나타나는 감정/판단/믿음/의견/기분 등의 주관적인 요소를 분석하는 기법 총칭. 소셜 미디어 감정 분석, 영화나 제품에 대한 긍정 또는 리뷰, 여론조사 의견 분석등의 다양한 영역에서 활용. 지도학습 뿐만 아니라 비지도학습(감성 Dictionary라는게 있음)을 이용해 적용할 수 있음.|\n",
    "|텍스트 요약(Summarization) | 텍스트 내에서 중요한 주제나 중심 사상을 추출하는 기법. 대표적으로 토픽 모델링(Topic Modeling)이 있다|\n",
    "|텍스트 군집화와 유사도 측정 | 비슷한 유형의 문서에 대해 군집화를 수행하는 기법. 텍스트 분류를 비지도 학습으로 수행하는 방법의 일환으로 사용될 수 있음. 유사도 측정 역시 문서들간의 유사도를 측정해 비슷한 문서끼리 모을 수 있는 방법|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>텍스트 분석 머신러닝 수행 프로세스</h2><br>\n",
    "\n",
    "머신러닝을 한다면 데이터가 있어야했다. 데이터는 피쳐가 있어야했다. 그 피쳐들이 전부다 숫자로 되어있었다.\n",
    "\n",
    "그 패턴을 계속적으로 학습을 하면서 예측과 평가를 할 수 있었는데\n",
    "\n",
    "텍스트는 어떻게 피쳐로 만들 수 있을까? 이게 바로 Feature Vectorization이다.\n",
    "\n",
    "\n",
    "대표적으로 Bag of Words가 있고 Word2Vec이 있다.\n",
    "\n",
    "\n",
    "단어들을 Feature로 만들 것임. 수천개건 수만개건. 그리고 그 단어가 뜻하는 것을 보통 이 Feature 값으로 만드는데 \n",
    "\n",
    "이 단어들을 카운트할 수도 있고 다른 정규화를 할 수 도 있다.\n",
    "\n",
    "결국 이 Text 문서를 사전가공을 한다. Feature Vectorization으로 가기전에 깔끔하게 가공. \n",
    "\n",
    "그리고 Vectorization 후 Vector가 되어 있으면 머신러닝 알고리즘으로 학습을 할 수 있다.\n",
    "\n",
    "<img src=\"./img/TextAnalysisProcess.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>파이썬 기반의 NLP, 텍스트 분석 패키지</h2><br>\n",
    "\n",
    "많은 것들이 있는데 대표적으로 3개.\n",
    "\n",
    "왜 케라스 텐서플로우 파이토치는 없나요? 라고 할 수는 있는데\n",
    "\n",
    "알고리즘이 있는 패키지가 아니라 전반적으로 텍스트 만을 위한 패키지를 말하는거임.\n",
    "\n",
    "텍스트 분석을 한다는건 많은 유형들이 필요함. 필터링은 어떻게 할 것이냐? 스타보드는 어떻게 정의를 할 거냐? 말뭉치는 또 어떻게?\n",
    "\n",
    "어근분석을 위해서 다양한 어간 추출(Stemming) 표제어 추출(Lemmatization) 은 어떻게 할 것이냐\n",
    "\n",
    "POS 태깅 (품사)은 어떻게 붙일것이며.. 이러한 유형들이 텍스트 분석을 하기 위해서 사전에 많은 사항들이 필요하다.\n",
    "\n",
    "그것들을 핵심 알고리즘과 유틸리티의 결합이 되서 편리하게 텍스트 분석을 제공하는 패키지 유형들이\n",
    "\n",
    "NLTK, GENSIM, SpaCy등이 있다는 것임. \n",
    "\n",
    "\n",
    "<img src=\"./img/PythonNLP1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>텍스트 전처리 - 텍스트 정규화(텍스트 전처리를 텍스트 정규화라고도 함)</h2><br>\n",
    "\n",
    "|||\n",
    "|:--:|:--:|\n",
    "|클렌징(Cleansing)| 텍스트에서 분석에 오히려 방해가 되는 불필요한 문자, 기호 등을 사전에 제거하는 작업. 예를 들어 HTML, XML 태그나 특정 기호 등을 사전에 제거.|\n",
    "|토큰화(Tokenization)|문장 토큰화, 단어 토큰화, n-gram|\n",
    "|필터링/스톱워드 제거/ 절차 수정|불필요한 단어나 분석에 큰 의미가 없는 단어(a, the, is, will등) 그리고 잘못된 철자 수정|\n",
    "|Stemming / Lemmatization|어근(단어 원형) 추출, Lemmatization이 Stemming 보다 정교하고 의미론적 기반에서 단어 원형을 찾아줌|\n",
    "\n",
    " --- \n",
    "\n",
    "\n",
    "<img src=\"./img/TexPreProcessing1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>N-gram</h2><br>\n",
    "\n",
    "칼같이 잘라버리면 문맥적인 의미가 있는데 그런게 다 날라가게 되어버린다. \n",
    "\n",
    "<img src=\"./img/NGRAM.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
