{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 텍스트 분석 Summary</h1>\n",
    "\n",
    "* 텍스트 분석 머신러닝 프로세스: 전처리 된 텍스트 들을 피처벡터화를 한 배열에 ML 학습/ 예측/ 평가를 수행했었다.\n",
    "\n",
    "* 텍스트 전처리\n",
    "\n",
    "클린징: HTML 태그라던가 불필요한 여러 텍스트를 클렌징하는 것.\n",
    "토큰화: 단어 기반으로 토큰화 (NGRAM을 썼다 주로)\n",
    "필터링/스톱워드: 필요없는 단어라던가 the, will 같은 스톱워드 제거.\n",
    "어근화 작업: 3인칭 단수에 s 가 붙고 이런것들을 어근화\n",
    "\n",
    "* 피처 벡터화\n",
    "이 단어들을 피처벡터화하는 것. BOG(Bag of Words) 단어의 순서가 보장되지 않는 피처 벡터화. \n",
    "단순 카운트 기반: 다큐먼트에 나타난 단어의 단순 회수만 기반\n",
    "TF-IDF: 너무 자주 나타난 것에는 오히려 패널티를 가하는 것. 긴 문서일 때는 오히려 이걸 사용(일반적으로는()\n",
    "\n",
    "* 텍스트 분석 주요영역\n",
    "\n",
    "텍스트 분류: 지도 학습과 똑같다. 단지 피처 벡터화된 행렬에 대해서 기반을 해서 학습을 하고 예측 분류를 한다는 차이만 있었음.\n",
    "감성 분석: 지도 학습 기반, 감성 사전 기반\n",
    "텍스트 요약: 대표적인, 토픽 모델링. 해당 문서에 여러가지 주제들을 확률 분포에 따라서 추정을 해가는 방식.\n",
    "텍스트의 군집화: 비슷한 문서끼리 군집으로 클러스터링하는 것. 유사도: A문서가 B 문서와 얼마나 유사한지.\n",
    "\n",
    "* 한글NLP\n",
    "\n",
    "* 비정형 데이터와 정형 데이터 결합을 통한 예측 분석:메루카리를 사례로 했음.\n",
    "\n",
    "<img src=\"./img/TextSummary1.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
