{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장 평가(Evaluation)\n",
    "\n",
    "### 분류(Classification) 성능 평가 지표\n",
    "* 정확도(Accuracy) → 이진분류에선 잘 쓰이지 않음\n",
    "* 오차행렬(Confusion Matrix)\n",
    "* 정밀도 (Prescision)\n",
    "* 재현율 (Recall)\n",
    "* F1 스코어\n",
    "* ROC AUC → 이진분류일때 많이 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1 Accuracy(정확도)\n",
    "\n",
    "정확도(Accuracy) = 예측 결과가 동일한 데이터 건수 / 전체 예측 데이터 건수\n",
    "\n",
    "* 정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표. 하지만 이진 분류의 경우 데이터의 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에\n",
    "정확도 수치 하나만 가지고 성능을 평가하지 않음\n",
    "\n",
    "* 특히 정확도는 불균형한(imbalanced) 레이블 값 분포에서 ML 모델의 성능을 판단할 경우, 적합한 평가 지표가 아니다.\n",
    "\n",
    "\n",
    "예: 신용카드 데이터 1만건 중 1건만 사기일 경우.\n",
    "\n",
    "\n",
    "다른 예:\n",
    "1. 타이타닉 생존자 예측에서 여성은 모두 생존으로 판별\n",
    "If Sex= '여성' \n",
    "\n",
    "생존\n",
    "\n",
    "2. MNIST multi classification에서 binary classification으로 변경\n",
    "\n",
    "MNIST는 0에서부터 9로 레이블을 매기는데.\n",
    "이걸 살짝 바꿔서 0-9까지 숫자중에 7이냐 아니냐를 하게되면 1/10인 7만 TRUE, 나머진 FALSE가 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "#먼저 더미 클래스파이어를 만들 것임. 사이킷런에서 쓸 수 있는것. 사이킷런은 기본적으로 \n",
    "#Estimator에서 분류일 경우 classfier 와 회귀일 경우 regressor를 만든다. \n",
    "\n",
    "\n",
    "# 생성자 안에 BaseEstimator 부모 클래스를 넣어서 상속을 받는다.\n",
    "# 그 안에 classfier에 가장 기반이 되는 메소드 fit 과 predict를 직접 만든다.\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit( ) 메소드는 아무것도 학습하지 않음. \n",
    "    def fit(self, X , y=None):\n",
    "        pass\n",
    "    \n",
    "    # predict( ) 메소드는 단순히 Sex feature가 1(남자) 이면 0(사망) , 그렇지 않으면 1 로 예측함. \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( ( X.shape[0], 1 )) #뒤에 1은 2차원으로 명확하게 하겠다는건데 안써도 되긴 한다.\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행. \n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train ,y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test , mypredictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과를 보면 성별이 남자인거로만해도 정확도가 78퍼가 나와버림. 특별한 알고리즘이 없이 남성을 사망, 여성을 생존으로만 해도 이렇게 나와버림."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제부턴 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환(뭐가 들어오더라도)\n",
    "    def predict(self,X):\n",
    "        return np.zeros( (len(X), 1) , dtype=bool)\n",
    "\n",
    "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print(\"### digits.data.shape:\", digits.data.shape)\n",
    "print(digits.target)\n",
    "print(\"### digits.target.shape:\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "[[ 0.  0.  5. ...  0.  0.  0.]\n",
    " [ 0.  0.  0. ... 10.  0.  0.]\n",
    " [ 0.  0.  0. ... 16.  9.  0.]\n",
    " ...\n",
    " [ 0.  0.  1. ...  6.  0.  0.]\n",
    " [ 0.  0.  2. ... 12.  0.  0.]\n",
    " [ 0.  0. 10. ... 12.  1.  0.]]\n",
    "### digits.data.shape: (1797, 64)\n",
    "[0 1 2 ... 8 9 8]\n",
    "### digits.target.shape: (1797,)\n",
    "~~~\n",
    "8x8을 풀어서 64. 1797의 row가 있는 것.\n",
    "\n",
    "타겟은 0이면 0, 1이면 1... 레이블.1797 1차원 쉐이프."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "digits.target == 7\n",
    "~~~\n",
    "이런식으로하면 불리안 값으로 어레이가 생긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환. \n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0 과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인. \n",
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0 과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train , y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리: 정확도는 이진분류일 경우 이렇게 양날의 검이 되므로 잘 사용하지 않는다.\n",
    "밑에서부터 이진분류일 때 자주 사용하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix ( 오차행렬 )\n",
    "\n",
    "오차행렬은 이진 분류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표\n",
    "\n",
    "|실제 클래스(Acutual Class) |예측클래스|(predicted Class)|\n",
    "|:-----:|:---------:|:----------:|\n",
    "|       |Negative(0)|Positive (1)|\n",
    "|Negative(0)| TN(True Negative)| FP (Flase Positive)|\n",
    "|Positive(1)|FN(False Negative)| TP (True Positive)|\n",
    "\n",
    "#### 의미\n",
    "\n",
    "**TN**은 예측을 네거티브로 했는데 True, 맞았다. **FP**는 실제로는 Negative인데 Positive로 예측했다. 틀렸다.\n",
    "\n",
    "\n",
    "**PN**은 예측을 네거티브로 했는데 False, 틀렸다. **TP**는 실제로 positive 인데 예측도 positive로 했다. 맞았다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 앞절의 예측 결과인 fakepred와 실제 결과인 y_test의 Confusion Matrix출력\n",
    "confusion_matrix(y_test , fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "405 는 TN, 45는 FN.\n",
    "\n",
    "- TP는 0. Positive로 예측이 한 건도 성공하지 않음.\n",
    "- 이와 더불어 FP가 0이므로 Positive로 예측 자체를 수행하지 않음을 알 수 있음.\n",
    "\n",
    "TN이 무려 405개가 나와서 정확도가 90퍼센트나 나와버렸다. 그래서 이런 불균형한 데이터 셋에선 정확도를 쓰면 안됨\n",
    "\n",
    "**정확도 = 예측 결과와 실제 값이 동일한 건수/ 전체 데이터 수 = (TN + TP)/(TN + FP + FN + TP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정밀도(Precision) 과 재현율(Recall)\n",
    "이진분류에서 많이 쓰인다.\n",
    "\n",
    "\n",
    "|실제 클래스(Acutual Class) |예측클래스|(predicted Class)|\n",
    "|:-----:|:---------:|:----------:|\n",
    "|       |Negative(0)|Positive (1)|\n",
    "|Negative(0)| TN(True Negative)| FP (Flase Positive)|\n",
    "|       |405개      |       0     |\n",
    "|Positive(1)|FN(False Negative)| TP (True Positive)|\n",
    "|       |45개      |      0      |\n",
    "\n",
    "오차행렬에서 쉽게 계산할 수 있다.\n",
    "\n",
    "   * **정밀도 = TP / (FP+TP)**\n",
    "   * **재현율 = TP / (FN+TP)**\n",
    "정밀도는 FP가 낮아져야 높아진다.\n",
    "재현율은 FN이 낮아져야 된다.\n",
    "\n",
    "왜냐? P로 예측을 한게 틀리는 값이 낮아져야 정밀도가 높아지고\n",
    "FN이 뜻하는건 예측을 N으로 한건데 틀렸다. 즉 실제 값이 Positive라는 것\n",
    "\n",
    "* 정밀도는 **예측을 Positive로 한 대상** 중에 예측과 실제 값이 positive로 일치한 데이터의 비율\n",
    "* 재현율은 **실제 값이 positive 인 대상** 중에 예측과 실제 값이 positive로 일치한 데이터의 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런의 정밀도, 재현율\n",
    "\n",
    "* 정밀도는 precision_score( ), 재현율은 recall_score( ) 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MyFakeClassifier의 예측 결과로 정밀도와 재현율 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.0\n",
      "재현율: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sang-woolee/Library/Python/3.6/lib/python/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score\n",
    "\n",
    "print(\"정밀도:\", precision_score(y_test, fakepred))\n",
    "print(\"재현율:\", recall_score(y_test, fakepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과 두개다 0 이 나오는 이유는  \n",
    "둘다 TP가 0이다. 그래서 분자가 0이므로 정밀도, 재현율 다 0이 나온다.  \n",
    "여기서 MyFakeClassifier가 못 쓰는 모델이구나 라는게 들통이 나는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
    "\n",
    "# 새로운 함수를 하나 만들어서, 실제 Y 값과 예측 Y 값을 넣을것. 거기서 오차율, 정확도, 정밀도, 재현율 구하는 함수를 만듦.\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할. \n",
    "titanic_df = pd.read_csv('./titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter = 1000)#default max_iter =100인데 더 필요해서 수정함.\n",
    "\n",
    "lr_clf.fit(X_train , y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision/Recall Trade-off 정밀도/ 재현율 트레이드 오프\n",
    "\n",
    "#### 업무에 따른 재현율과 정밀도의 상대적 중요도\n",
    "\n",
    "* 재현율이 상대적으로 더 중요한 지표인 경우는 실제 Positive 양성인 데이터 예측을 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우: 암 진단, 금융사기 판별. **암인데, 암이 아닌데요? 라던가. 사기인데 사기 아닌데요? 라던가**\n",
    "* 정밀도가 상대적으로 더 중요한 지표인 경우는 실제 Negative 음성인 데이터 예측을 Positive 양성으로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우: 스팸 메일 **정상 메일인데 스팸 메일이라고 판단해서 중요한 메일이 스팸에 되어버림.업무적으로 문제가 크게 생길 수 있다**\n",
    "\n",
    "✰ 불균형한 레이블 클래스를 가지는 이진 분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야하는 매우 적은 수의 결과값에 Positive를 설정해 1값을 부여하고, 그렇지 않은 경우는 Negative로 0 값을 일반적으로 부여합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류하려는 **업무 특성상 정밀도 또는 재현율이 특별히 강조**돼야 할 경우 **분류의 결정 임계값(threshold)를 조정해 정밀도 또는 재현율의 수치를 높일 수 있습니다.**\n",
    "- 하지만 정밀도와 재현율은 **상호 보완적**인 평가 지표이기 때문에 어느 **한쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉽다.** 이를 **정밀도/ 재현율의 트레이드 오프(Trade-off)라고 부른다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사이킷런 Estimator 객체의 predict_proba ( )메소드는 분류 결정 예측 확률을 반환한다.\n",
    "* 이를 이용하면 임의로 분류 결정 임계값을 조정하면서 예측 확률을 변경할 수 있다.\n",
    "\n",
    "**predict_proba( ) 메소드 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred  = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Binarizer 활용 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[ 1, -1,  2],\n",
    "     [ 2,  0,  0],\n",
    "     [ 0,  1.1, 1.2]]\n",
    "\n",
    "# threshold 기준값보다 같거나 작으면 0을, 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.1)                     \n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 분류 결정 임계값 0.5 기반에서 Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Binarizer의 threshold 설정값. 분류 결정 임곗값임.  \n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba( ) 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer를 적용\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 분류 결정 임계값 0.4 기반에서 Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임곗값을 0.5에서 0.4로 낮춤  \n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test , custom_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 여러개의 분류 결정 임곗값을 변경하면서  Binarizer를 이용하여 예측값 변환 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트를 수행할 모든 임곗값을 리스트 객체로 저장. \n",
    "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds list객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict)\n",
    "\n",
    "get_eval_by_threshold(y_test ,pred_proba[:,1].reshape(-1,1), thresholds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** precision_recall_curve( ) 를 이용하여 임곗값에 따른 정밀도-재현율 값 추출 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 \n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1 )\n",
    "print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n",
    "print('반환된 precisions 배열의 Shape:', precisions.shape)\n",
    "print('반환된 recalls 배열의 Shape:', recalls.shape)\n",
    "\n",
    "print(\"thresholds 5 sample:\", thresholds[:5])\n",
    "print(\"precisions 5 sample:\", precisions[:5])\n",
    "print(\"recalls 5 sample:\", recalls[:5])\n",
    "\n",
    "#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출. \n",
    "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
    "print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 임곗값의 변경에 따른 정밀도-재현율 변화 곡선을 그림 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "f1 = f1_score(y_test , pred)\n",
    "print('F1 스코어: {0:.4f}'.format(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    # F1 스코어 추가\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # f1 score print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "thresholds = [0.4 , 0.45 , 0.50 , 0.55 , 0.60]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5 ROC Curve와 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "# 반환된 임곗값 배열 로우가 47건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(y_test , pred_proba_c1):\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환 받음. \n",
    "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
    "\n",
    "    # ROC Curve를 plot 곡선으로 그림. \n",
    "    plt.plot(fprs , tprs, label='ROC')\n",
    "    # 가운데 대각선 직선을 그림. \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    \n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1); plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "### 아래는 roc_auc_score()의 인자를 잘못 입력한 것으로, 책에서 수정이 필요한 부분입니다. \n",
    "### 책에서는 roc_auc_score(y_test, pred)로 예측 타겟값을 입력하였으나 \n",
    "### roc_auc_score(y_test, y_score)로 y_score는 predict_proba()로 호출된 예측 확률 ndarray중 Positive 열에 해당하는 ndarray입니다. \n",
    "\n",
    "#pred = lr_clf.predict(X_test)\n",
    "#roc_score = roc_auc_score(y_test, pred)\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "          F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
